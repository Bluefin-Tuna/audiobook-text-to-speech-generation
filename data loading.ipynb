{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data(paths):\n",
    "    sentence_spectrograph = {}\n",
    "    for path in paths:\n",
    "        speakers = os.listdir(path)\n",
    "        print(path)\n",
    "        for speaker in speakers:\n",
    "            chapter_path = path + '\\{}'.format(speaker)\n",
    "            chapters = os.listdir(chapter_path)\n",
    "            sentence_spectrograph[speaker] = []\n",
    "            for chapter in chapters:\n",
    "                main_path = chapter_path + '\\{}'.format(chapter)\n",
    "                main = os.listdir(main_path)\n",
    "                data_pair = []\n",
    "                for data in main[2:]:\n",
    "                    data_path = main_path + '\\{}'.format(data)\n",
    "                    if(data.split('.')[1] == 'original' and data.split('.')[1] == 'txt'):\n",
    "                        sentence = open(data_path, 'r').read()\n",
    "                        data_pair.append(sentence)\n",
    "                    elif(data.split('.')[1] == 'wav'):\n",
    "                        sample_rate, samples = wavfile.read(data_path)\n",
    "                        frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "                        data_pair.append(spectrogram)\n",
    "                    \n",
    "                    if(len(data_pair) == 2):\n",
    "                        sentence_spectrograph[speaker].append(data_pair)\n",
    "                        data_pair = []\n",
    "            \n",
    "    return sentence_spectrograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_paths = [r'C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Training\\train-clean-360']\n",
    "\n",
    "test_paths = [r'C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Test\\test-clean', \n",
    "              r'C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Test\\test-other']\n",
    "\n",
    "validation_paths = [r'C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Development\\dev-clean', \n",
    "              r'C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Development\\dev-other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentences(data):\n",
    "    new_data = {}\n",
    "    for speaker in data.keys():\n",
    "        data_pairs = data[speaker]\n",
    "        new_data[speaker] = []\n",
    "        for data_pair in data_pairs:\n",
    "            sentence = data_pair[0]\n",
    "            sentence = re.sub('([.,!?()\"])', r' \\1 ', sentence)\n",
    "            sentence = sentence.replace(\"  \", \" \")\n",
    "            sentence = sentence.strip()\n",
    "            new_data_pair = [sentence, data_pair[1]]\n",
    "            new_data[speaker].append(new_data_pair)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Training\\train-clean-360\n",
      "C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Development\\dev-clean\n",
      "C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Development\\dev-other\n",
      "C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Test\\test-clean\n",
      "C:\\Users\\tanus\\Deep Learning\\Current Datasets\\LibriTTS\\Test\\test-other\n"
     ]
    }
   ],
   "source": [
    "training_data = retrieve_data(training_paths)\n",
    "validation_data = retrieve_data(validation_paths)\n",
    "test_paths = retrieve_data(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
